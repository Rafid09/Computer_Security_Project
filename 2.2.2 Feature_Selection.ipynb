{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f1200c",
   "metadata": {},
   "source": [
    "## 2.2.2 Feature Selection Methods (Gradient Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30049787",
   "metadata": {},
   "source": [
    "## Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227c3c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  47\n",
      "Testing Accuracy:  0.9301724137931034\n",
      "Training Accuracy:  0.9977365811597327\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  94\n",
      "Testing Accuracy:  0.9387931034482758\n",
      "Training Accuracy:  0.9984910541064884\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  141\n",
      "Testing Accuracy:  0.9469827586206897\n",
      "Training Accuracy:  0.998598835956025\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  188\n",
      "Testing Accuracy:  0.9431034482758621\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  235\n",
      "Testing Accuracy:  0.9461206896551724\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  282\n",
      "Testing Accuracy:  0.9469827586206897\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  329\n",
      "Testing Accuracy:  0.9495689655172413\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  376\n",
      "Testing Accuracy:  0.9491379310344827\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  423\n",
      "Testing Accuracy:  0.95\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pearson_selection(X, y, num_of_feat):\n",
    "    fs = SelectKBest(score_func=f_regression, k=num_of_feat)\n",
    "    fit = fs.fit(X, y)\n",
    "\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Best_columns', 'Score_pearson']\n",
    "\n",
    "    lyst = featureScores.nlargest(num_of_feat, 'Score_pearson')\n",
    "\n",
    "    pearson_features = list(lyst['Best_columns'])\n",
    "    return pearson_features\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"feature_vectors_syscallsbinders_frequency_5_Cat.csv\")\n",
    "target = \"Class\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "#X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(47, len(X.columns), 47):\n",
    "    print(\"Number of columns: \", i)\n",
    "    pearson_list = pearson_selection(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, pearson_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    gbc = GradientBoostingClassifier(n_estimators=236, max_depth=11, random_state=0)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = gbc.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = gbc.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f225127e",
   "metadata": {},
   "source": [
    "## Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c11f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  47\n",
      "Testing Accuracy:  0.9357758620689656\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  94\n",
      "Testing Accuracy:  0.9452586206896552\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  141\n",
      "Testing Accuracy:  0.9456896551724138\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  188\n",
      "Testing Accuracy:  0.9469827586206897\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  235\n",
      "Testing Accuracy:  0.9508620689655173\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  282\n",
      "Testing Accuracy:  0.9495689655172413\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  329\n",
      "Testing Accuracy:  0.9521551724137931\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  376\n",
      "Testing Accuracy:  0.9504310344827587\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  423\n",
      "Testing Accuracy:  0.9508620689655173\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def mutual_info_selection(X, y, num_of_feat):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=num_of_feat)\n",
    "    fit = fs.fit(X, y)\n",
    "\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Best_columns', 'Score_mutual_info']\n",
    "\n",
    "    lyst = featureScores.nlargest(num_of_feat, 'Score_mutual_info')\n",
    "\n",
    "    mutual_info_features = list(lyst['Best_columns'])\n",
    "    return mutual_info_features\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"feature_vectors_syscallsbinders_frequency_5_Cat.csv\")\n",
    "target = \"Class\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "# X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(47, len(X.columns), 47):\n",
    "    print(\"Number of columns: \", i)\n",
    "    mutual_info_list = mutual_info_selection(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, mutual_info_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    gbc = GradientBoostingClassifier(n_estimators=236, max_depth=11, random_state=0)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = gbc.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = gbc.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61832e4c",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6a8250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.feature_selection import RFE\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\n\\ndef rfe_selection(X, y, num_of_feat):\\n    model = LogisticRegression(max_iter=1000)\\n    rfe = RFE(model, n_features_to_select=num_of_feat)\\n    fit = rfe.fit(X, y)\\n\\n    feature_ranks = pd.DataFrame(fit.ranking_, index=X.columns, columns=[\\'Rank\\'])\\n    selected_features = feature_ranks[feature_ranks[\\'Rank\\'] == 1].index.tolist()\\n    \\n    return selected_features\\n\\n# Load your dataset\\ndf = pd.read_csv(\"permission-based_malware_2.csv\")\\ntarget = \"CLASS\"\\n\\nX = df.loc[:, df.columns != target]\\nX = X.loc[:, X.columns != \"NAME\"]\\ny = df[target]\\n\\n# Iterate over different numbers of features\\nfor i in range(50, len(X.columns), 50):\\n    print(\"Number of columns: \", i)\\n    rfe_list = rfe_selection(X, y, i)\\n\\n    X_ = df.loc[:, rfe_list]\\n    y_ = df[target]\\n\\n    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\\n\\n    gbc = GradientBoostingClassifier(n_estimators=186, max_depth=6, random_state=0)\\n    gbc.fit(X_train, y_train)\\n    \\n    y_pred_test = gbc.predict(X_test)\\n    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\\n    \\n    y_pred_train = gbc.predict(X_train)\\n    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\\n    print(\"___________________________________________________________________________________________\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def rfe_selection(X, y, num_of_feat):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    rfe = RFE(model, n_features_to_select=num_of_feat)\n",
    "    fit = rfe.fit(X, y)\n",
    "\n",
    "    feature_ranks = pd.DataFrame(fit.ranking_, index=X.columns, columns=['Rank'])\n",
    "    selected_features = feature_ranks[feature_ranks['Rank'] == 1].index.tolist()\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"permission-based_malware_2.csv\")\n",
    "target = \"CLASS\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(50, len(X.columns), 50):\n",
    "    print(\"Number of columns: \", i)\n",
    "    rfe_list = rfe_selection(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, rfe_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    gbc = GradientBoostingClassifier(n_estimators=186, max_depth=6, random_state=0)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = gbc.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = gbc.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367607d",
   "metadata": {},
   "source": [
    "## Chi-square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317681be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  47\n",
      "Testing Accuracy:  0.944396551724138\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  94\n",
      "Testing Accuracy:  0.9474137931034483\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  141\n",
      "Testing Accuracy:  0.944396551724138\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  188\n",
      "Testing Accuracy:  0.9461206896551724\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  235\n",
      "Testing Accuracy:  0.95\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  282\n",
      "Testing Accuracy:  0.9508620689655173\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  329\n",
      "Testing Accuracy:  0.9512931034482759\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  376\n",
      "Testing Accuracy:  0.95\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  423\n",
      "Testing Accuracy:  0.95\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def chi2_selection(X, y, num_of_feat):\n",
    "    fs = SelectKBest(score_func=chi2, k=num_of_feat)\n",
    "    fit = fs.fit(X, y)\n",
    "\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Best_columns', 'Score_chi2']\n",
    "\n",
    "    lyst = featureScores.nlargest(num_of_feat, 'Score_chi2')\n",
    "\n",
    "    chi2_features = list(lyst['Best_columns'])\n",
    "    return chi2_features\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"feature_vectors_syscallsbinders_frequency_5_Cat.csv\")\n",
    "target = \"Class\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "#X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(47, len(X.columns), 47):\n",
    "    print(\"Number of columns: \", i)\n",
    "    chi2_list = chi2_selection(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, chi2_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    gbc = GradientBoostingClassifier(n_estimators=236, max_depth=11, random_state=0)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = gbc.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = gbc.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680fdf59",
   "metadata": {},
   "source": [
    "## ANOVA F-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f582b1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  47\n",
      "Testing Accuracy:  0.9271551724137931\n",
      "Training Accuracy:  0.9952575986203923\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  94\n",
      "Testing Accuracy:  0.9387931034482758\n",
      "Training Accuracy:  0.9978443630092693\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  141\n",
      "Testing Accuracy:  0.9487068965517241\n",
      "Training Accuracy:  0.998598835956025\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  188\n",
      "Testing Accuracy:  0.9482758620689655\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  235\n",
      "Testing Accuracy:  0.9431034482758621\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  282\n",
      "Testing Accuracy:  0.9482758620689655\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  329\n",
      "Testing Accuracy:  0.95\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  376\n",
      "Testing Accuracy:  0.9517241379310345\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  423\n",
      "Testing Accuracy:  0.9504310344827587\n",
      "Training Accuracy:  0.9987066178055616\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def anova_selection(X, y, num_of_feat):\n",
    "    fs = SelectKBest(score_func=f_classif, k=num_of_feat)\n",
    "    fit = fs.fit(X, y)\n",
    "\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Best_columns', 'Score_anova']\n",
    "\n",
    "    lyst = featureScores.nlargest(num_of_feat, 'Score_anova')\n",
    "\n",
    "    anova_features = list(lyst['Best_columns'])\n",
    "    return anova_features\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"feature_vectors_syscallsbinders_frequency_5_Cat.csv\")\n",
    "target = \"Class\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "# X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(47, len(X.columns), 47):\n",
    "    print(\"Number of columns: \", i)\n",
    "    anova_list = anova_selection(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, anova_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    gbc = GradientBoostingClassifier(n_estimators=236, max_depth=11, random_state=0)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = gbc.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = gbc.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computer_Security",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
